# tokenizing
from nltk.tokenize import sent_tokenize,word_tokenize
sentence = "Ram is a good boy. He likes arrow.He is nice like that.He is awesome "
print(sent_tokenize(sentence))
print(word_tokenize(sentence))
